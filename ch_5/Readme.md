# Ансамбль моделей для прогнозирования временных рядов

Этот ансамбль представляет собой комбинированный метод прогнозирования временных рядов, который объединяет предсказания четырёх различных моделей:

- **Exponential Smoothing (Экспоненциальное сглаживание)**
- **Random Forest Regressor (Случайный лес)**
- **Gradient Boosting Regressor (Градиентный бустинг)**
- **XGBoost Regressor**

## Метод ансамблирования
Ансамблирование реализовано с использованием простого усреднения предсказаний всех моделей.  
Для каждой временной точки прогноз берётся как среднее значение предсказаний всех моделей, что позволяет уменьшить возможные ошибки отдельных моделей и сделать прогноз более стабильным.

---

## Подробное описание моделей

### 1. Exponential Smoothing (Экспоненциальное сглаживание)
- Использует метод Хольта-Винтерса для прогнозирования временного ряда.
- Захватывает тренд (`trend='add'`) и прогнозирует будущее на основе последних значений.
- Хорош для моделирования плавных временных рядов без резких изменений.

### 2. Random Forest Regressor
- Модель ансамблевого обучения, основанная на деревьях решений.
- Каждое дерево обучается на случайной подвыборке данных, что делает модель устойчивой к шуму.
- Хорошо работает при наличии сложных зависимостей и нелинейных закономерностей.

### 3. Gradient Boosting Regressor
- Использует последовательное обучение деревьев решений, где каждое следующее дерево исправляет ошибки предыдущего.
- Хорошо подходит для сложных зависимостей.
- Умеет моделировать долгосрочные тренды и особенности ряда.

### 4. XGBoost Regressor
- Улучшенная версия градиентного бустинга, оптимизированная по скорости и точности.
- Использует регуляризацию для уменьшения переобучения.
- Особенно хорошо справляется с данными с высокой вариативностью.

---

Сравнение метрик моделей

| Model                  | MSE        | MAE      | RMSE     | MAPE   | R²     |
|------------------------|-----------|----------|----------|--------|--------|
| **Decision Tree**      | 13356.55  | 39.75    | 52.59    | 0.0199 | 0.3932 |
| **Ensemble**           | 6438.44   | 27.93    | 36.90    | 0.0152 | 0.6525 |
| **Exponential Smoothing** | 6142.96   | 27.29    | 35.40    | 0.0146 | 0.6235 |
| **Gradient Boosting**  | 7327.06   | 30.49    | 40.83    | 0.0174 | 0.5523 |
| **LGBM**              | 8035.96   | 33.18    | 44.51    | 0.0218 | 0.4149 |
| **Random Forest**      | 6907.29   | 29.26    | 38.40    | 0.0165 | 0.6357 |
| **XGBoost**           | 8567.84   | 31.50    | 42.18    | 0.0171 | 0.5694 |
| **k-NN**              | 12135.87  | 39.03    | 50.35    | 0.0230 | 0.2408 |

---

Ансамблевая модель – **лучший вариант среди всех протестированных алгоритмов**. Она **снижает ошибки и улучшает R²**, комбинируя преимущества разных подходов.  

- Если главная цель – **минимизировать ошибку** (MSE, MAE, RMSE, MAPE), то **Exponential Smoothing** является хорошей альтернативой.
- Если важен **баланс между точностью и объясняющей способностью**, то **ансамбль – оптимальный выбор**.
- Простые модели, такие как **Decision Tree и k-NN**, показывают **значительно худшие результаты** и не рекомендуются для использования.

Таким образом, ансамбль является **наиболее стабильной и точной моделью для прогнозирования**.
