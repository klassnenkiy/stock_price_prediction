# Описание Модели

В качестве DL подхода своего проекта мною была выбрна рекуррентная нейронная сеть RNN, использующая архитектуру **LSTM**  и **GRU**, так как они активно и часто используются для прогнозирования цен акций на основе исторических данных.

- **LSTM-GRU модель**: моя модель сочетает два типа рекуррентных слоёв - **LSTM** и **GRU**. Это позволяет ей улавливать как краткосрочные, так и долгосрочные зависимости в данных, что особенно важно для временных рядов, таких как данные о ценах на акции.
- **LSTM**: Этот слой помогает модели эффективно запоминать долгосрочные зависимости и решать проблему исчезающего градиента, что важно при обучении на длинных последовательностях.
- **GRU**: **GRU** является более лёгкой альтернативой **LSTM**, улучшая вычислительную эффективность, при этом сохраняет способность захватывать долгосрочные зависимости.

#### **Данные**:
- **Цена закрытия (CLOSE)**: Модель использует исторические данные о ценах закрытия акций. Данные очищаются от пропусков с помощью метода **forward fill**.
- **Волатильность**: Для улучшения прогноза добавляется дополнительный признак — волатильность, рассчитанная как стандартное отклонение цен закрытия за заданное окно (например, 20 дней). Это помогает модели учесть изменения в колебаниях цен, что особенно важно для высоковолатильных активов.
- **Данные о времени**: Каждая запись содержит информацию о дате сделки, которая используется для определения времени и тренда.

#### **Предобработка данных**:
- **Масштабирование**: Все данные (цены и волатильность) масштабируются с помощью **MinMaxScaler**, чтобы привести их к диапазону [0, 1]. Это важно для ускорения сходимости модели и улучшения её стабильности при обучении.
- **Заполнение пропусков**: Используется метод **forward fill** для заполнения пропущенных значений в столбце "CLOSE".

#### **Архитектура модели**:
- **LSTM слой**: Входной слой **LSTM** с 128 нейронами, который преобразует входные данные в последовательность признаков. Параметр **return_sequences=True** позволяет передавать выходные данные следующему слою.
- **Dropout**: Слой **Dropout(0.2)** используется для регуляризации модели, что помогает избежать переобучения, отключая случайные нейроны во время обучения.
- **GRU слой**: Далее применяется слой **GRU** с 64 нейронами, который помогает моделировать временные зависимости и снижает вычислительную нагрузку по сравнению с чистым **LSTM**.
- **Dropout**: Еще один слой **Dropout(0.2)** для предотвращения переобучения.
- **Dense слой**: Финальный полносвязный слой с 1 нейроном, который предсказывает цену закрытия акции на следующий день или через несколько дней.

#### **Обучение**:
- **Функция потерь**: Для обучения модели используется **Huber loss**. Эта функция потерь является более стабильной для наличия выбросов, что особенно полезно для данных о ценах акций.
- **Оптимизатор**: Для минимизации ошибки используется оптимизатор **Adam**, который является популярным и эффективным для задач машинного обучения.
- **EarlyStopping**: Для предотвращения переобучения добавлен callback **EarlyStopping**, который останавливает обучение, если модель не улучшает свою производительность в течение 10 эпох.

#### **Введение шума (волатильности)**:
Для того чтобы сделать прогноз более реалистичным и учитывать рыночные колебания, в модель добавляется **шум** на основе стандартного отклонения ошибок на тестовой выборке. Этот шум симулирует волатильность на рынке и добавляется к прогнозу на тестовой выборке и будущим прогнозам.

#### **Прогнозирование на будущее**:
Модель использует последние данные для создания прогноза на будущее, который затем корректируется добавлением **шумовых колебаний (волатильности)**.

Прогнозы на будущее создаются для заданного количества дней, и для этого модель обновляет окно данных после каждого предсказания.

#### **Оценка качества**:
Модель оценивается по **MSE** (Mean Squared Error), **MAE** (Mean Absolute Error), **RMSE** (Root Mean Squared Error), **MAPE** (Mean Absolute Percentage Error) и **R²** (коэффициент детерминации), которые помогают понять, насколько хорошо модель предсказывает фактические значения.

#### **другие особенности**:
- **Волатильность**: Включение волатильности в качестве дополнительного признака и добавление шума в прогнозы помогает модели лучше учитывать рыночные колебания и нестабильность, которые характерны для данных о ценах акций.
- **Обучение на тестах**: Модель обучается на исторических данных и проверяется на тестовых данных, после чего прогнозируются будущие значения с учётом волатильности.

# Результаты

### Результаты модели LSTM-GRU по тикерам голубых фишек

| Model   | Ticker | MSE         | MAE        | RMSE       | MAPE     | R²       |
|---------|--------|-------------|------------|------------|----------|----------|
| LSTM-GRU| PLZL   | 241112.94   | 404.17     | 491.03     | 0.0310   | 0.63397  |
| LSTM-GRU| SIBN   | 1094.02     | 26.81      | 33.08      | 0.0413   | 0.34366  |
| LSTM-GRU| NVTK   | 746.78      | 20.00      | 27.33      | 0.0210   | 0.47836  |
| LSTM-GRU| LKOH   | 37676.11    | 155.59     | 194.10     | 0.0231   | 0.47230  |
| LSTM-GRU| SBER   | 69.79       | 6.61       | 8.35       | 0.0260   | -0.16556 |
| LSTM-GRU| SBERP  | 73.35       | 6.95       | 8.56       | 0.0273   | -0.22745 |
| LSTM-GRU| ROSN   | 326.24      | 13.06      | 18.06      | 0.0272   | 0.29593  |
| LSTM-GRU| GAZP   | 30.15       | 3.77       | 5.49       | 0.0288   | 0.21524  |
| LSTM-GRU| TATN   | 621.85      | 21.42      | 24.94      | 0.0358   | 0.28916  |
| LSTM-GRU| TATNP  | 586.49      | 21.07      | 24.22      | 0.0351   | 0.31178  |
| LSTM-GRU| SNGS   | 1.37        | 0.89       | 1.17       | 0.0375   | -0.12511 |
| LSTM-GRU| SNGSP  | 4.57        | 1.54       | 2.14       | 0.0298   | 0.58630  |
| LSTM-GRU| CHMF   | 6502.48     | 70.79      | 80.64      | 0.0586   | -1.38641 |
| LSTM-GRU| NLMK   | 119.56      | 9.38       | 10.93      | 0.0704   | -0.42788 |

- Лучшие результаты: Модель лучше всего работает с тикерами SNGS и TATNP, где ошибки минимальны и показатели R² высокие.

- Проблемные тикеры: Для PLZL и CHMF прогнозы имеют большие ошибки, что может быть связано с высокой волатильностью этих акций или недостаточными признаками.

#### усредненный реузльтат по тикерам

| Model   | MSE         | MAE        | RMSE       | MAPE     | R²       |
|---------|-------------|------------|------------|----------|----------|
| LSTM-GRU| 20640.41    | 54.43      | 66.43      | 0.0352   | 0.0924   |


## Сравнение с ML моделями и бейзлайном


| Model               | MSE        | MAE        | RMSE       | MAPE     | R²       |
|---------------------|------------|------------|------------|----------|----------|
| Decision Tree       | 13356.55   | 39.75      | 52.59      | 0.0199   | 0.3932   |
| **Exponential Smoothing**| 6142.96    | 27.29      | 35.40      | 0.0146   | 0.6235   |
| Gradient Boosting   | 7327.06    | 30.49      | 40.83      | 0.0174   | 0.5523   |
| LGBM                | 8035.96    | 33.18      | 44.51      | 0.0218   | 0.4149   |
| Random Forest       | 6907.29    | 29.26      | 38.40      | 0.0165   | 0.6357   |
| XGBoost             | 8567.84    | 31.50      | 42.18      | 0.0171   | 0.5694   |
| k-NN                | 12135.87   | 39.03      | 50.35      | 0.0230   | 0.2408   |
| LSTM-GRU            | 20640.41   | 54.43      | 66.43      | 0.0352   | 0.0924   |
| Lin Reg (Baseline)   | 5632.40    | 26.14      | 33.91      | 0.0156   | 0.7898   |


Результат ожидаемо хуже? чем у мл моделей и бейзлайна, но это пока максимум, хотя положительный р квадрат в среднем по тикерам и ошибки больше всего в пару раз.

Возможно при должной настройке результат подойдет ближе к мл моделям и даже мб первзойдет его. Оставлю это исследование на дальнейшее изучение для финальной работы и ВКР.

Ссылка на колаб - https://colab.research.google.com/drive/1hT7fE9scjH5da6VhrkzWWu72zJs7G8QU#scrollTo=jdCme8ucB0dW

